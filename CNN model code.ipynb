{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.models import Sequential, model_from_json\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1/255,\n",
    "    rotation_range = 40,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale = 1/255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'cardataset/train/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ME357A~1.AMI\\AppData\\Local\\Temp/ipykernel_2044/3252234308.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m train_it = train_datagen.flow_from_directory(\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;34m'cardataset/train/'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mclass_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     target_size = (150,150))\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[1;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001b[0m\n\u001b[0;32m    974\u001b[0m             \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0my\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m     \"\"\"\n\u001b[1;32m--> 976\u001b[1;33m     return DirectoryIterator(\n\u001b[0m\u001b[0;32m    977\u001b[0m         \u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    978\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[0;32m    392\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dtype'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m     super(DirectoryIterator, self).__init__(\n\u001b[0m\u001b[0;32m    395\u001b[0m         \u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_data_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m         \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras_preprocessing\\image\\directory_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'cardataset/train/'"
     ]
    }
   ],
   "source": [
    "train_it = train_datagen.flow_from_directory(\n",
    "    'cardataset/train/', \n",
    "    class_mode='categorical', \n",
    "    batch_size=32, \n",
    "    target_size = (150,150))\n",
    "\n",
    "val_it = val_datagen.flow_from_directory(\n",
    "    'cardataset/test/', \n",
    "    class_mode='categorical', \n",
    "    batch_size=32,\n",
    "    target_size = (150,150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3,3), activation = 'relu', input_shape= (150,150,3)),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    \n",
    "    layers.Conv2D(64, (3,3), activation = 'relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Dropout(0.2),\n",
    "    \n",
    "    layers.Conv2D(128, (3,3), activation = 'relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Dropout(0.2),\n",
    "    \n",
    "    layers.Conv2D(128, (3,3), activation = 'relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Dropout(0.4),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "\n",
    "    layers.Dense(8, activation='softmax')\n",
    "])\n",
    "\n",
    "          \n",
    "model.compile(loss = \"categorical_crossentropy\",\n",
    "             optimizer = \"adam\",\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-3614528878e7>:3: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 666 steps, validate for 137 steps\n",
      "Epoch 1/100\n",
      "666/666 [==============================] - 1248s 2s/step - loss: 1.5846 - accuracy: 0.4101 - val_loss: 1.5127 - val_accuracy: 0.4744\n",
      "Epoch 2/100\n",
      "666/666 [==============================] - 1329s 2s/step - loss: 1.3978 - accuracy: 0.4873 - val_loss: 1.2995 - val_accuracy: 0.5354\n",
      "Epoch 3/100\n",
      "666/666 [==============================] - 1271s 2s/step - loss: 1.2921 - accuracy: 0.5292 - val_loss: 1.3562 - val_accuracy: 0.5210\n",
      "Epoch 4/100\n",
      "666/666 [==============================] - 1254s 2s/step - loss: 1.2171 - accuracy: 0.5596 - val_loss: 1.1889 - val_accuracy: 0.5781\n",
      "Epoch 5/100\n",
      "666/666 [==============================] - 1202s 2s/step - loss: 1.1649 - accuracy: 0.5791 - val_loss: 1.2239 - val_accuracy: 0.5525\n",
      "Epoch 6/100\n",
      "666/666 [==============================] - 820s 1s/step - loss: 1.1141 - accuracy: 0.6019 - val_loss: 1.1169 - val_accuracy: 0.6012\n",
      "Epoch 7/100\n",
      "666/666 [==============================] - 808s 1s/step - loss: 1.0781 - accuracy: 0.6160 - val_loss: 1.0536 - val_accuracy: 0.6236\n",
      "Epoch 8/100\n",
      "666/666 [==============================] - 811s 1s/step - loss: 1.0537 - accuracy: 0.6264 - val_loss: 1.0429 - val_accuracy: 0.6215\n",
      "Epoch 9/100\n",
      "666/666 [==============================] - 804s 1s/step - loss: 1.0301 - accuracy: 0.6357 - val_loss: 0.9764 - val_accuracy: 0.6569\n",
      "Epoch 10/100\n",
      "666/666 [==============================] - 801s 1s/step - loss: 0.9975 - accuracy: 0.6459 - val_loss: 0.9145 - val_accuracy: 0.6855\n",
      "Epoch 11/100\n",
      "666/666 [==============================] - 794s 1s/step - loss: 0.9758 - accuracy: 0.6525 - val_loss: 0.9615 - val_accuracy: 0.6581\n",
      "Epoch 12/100\n",
      "666/666 [==============================] - 795s 1s/step - loss: 0.9534 - accuracy: 0.6618 - val_loss: 0.9549 - val_accuracy: 0.6537\n",
      "Epoch 13/100\n",
      "666/666 [==============================] - 792s 1s/step - loss: 0.9441 - accuracy: 0.6663 - val_loss: 0.9200 - val_accuracy: 0.6779\n",
      "Epoch 14/100\n",
      "666/666 [==============================] - 883s 1s/step - loss: 0.9282 - accuracy: 0.6712 - val_loss: 0.8743 - val_accuracy: 0.6978\n",
      "Epoch 15/100\n",
      "666/666 [==============================] - 789s 1s/step - loss: 0.9129 - accuracy: 0.6797 - val_loss: 0.8742 - val_accuracy: 0.6962\n",
      "Epoch 16/100\n",
      "666/666 [==============================] - 773s 1s/step - loss: 0.8971 - accuracy: 0.6878 - val_loss: 0.9108 - val_accuracy: 0.6731\n",
      "Epoch 17/100\n",
      "666/666 [==============================] - 1315s 2s/step - loss: 0.8823 - accuracy: 0.6908 - val_loss: 0.9061 - val_accuracy: 0.6834\n",
      "Epoch 18/100\n",
      "666/666 [==============================] - 1391s 2s/step - loss: 0.8608 - accuracy: 0.6986 - val_loss: 0.8324 - val_accuracy: 0.7067\n",
      "Epoch 19/100\n",
      "666/666 [==============================] - 1390s 2s/step - loss: 0.8545 - accuracy: 0.7032 - val_loss: 0.8878 - val_accuracy: 0.6887\n",
      "Epoch 20/100\n",
      "666/666 [==============================] - 1327s 2s/step - loss: 0.8564 - accuracy: 0.7012 - val_loss: 0.8240 - val_accuracy: 0.7145\n",
      "Epoch 21/100\n",
      "666/666 [==============================] - 1243s 2s/step - loss: 0.8440 - accuracy: 0.7049 - val_loss: 0.9711 - val_accuracy: 0.6540\n",
      "Epoch 22/100\n",
      "666/666 [==============================] - 1155s 2s/step - loss: 0.8318 - accuracy: 0.7103 - val_loss: 0.8553 - val_accuracy: 0.7049\n",
      "Epoch 23/100\n",
      "666/666 [==============================] - 863s 1s/step - loss: 0.8260 - accuracy: 0.7127 - val_loss: 0.8396 - val_accuracy: 0.7104\n",
      "Epoch 24/100\n",
      "666/666 [==============================] - 830s 1s/step - loss: 0.8220 - accuracy: 0.7130 - val_loss: 0.7923 - val_accuracy: 0.7216\n",
      "Epoch 25/100\n",
      "666/666 [==============================] - 901s 1s/step - loss: 0.8082 - accuracy: 0.7193 - val_loss: 0.8732 - val_accuracy: 0.6891\n",
      "Epoch 26/100\n",
      "666/666 [==============================] - 812s 1s/step - loss: 0.8047 - accuracy: 0.7220 - val_loss: 0.8204 - val_accuracy: 0.7213\n",
      "Epoch 27/100\n",
      "666/666 [==============================] - 809s 1s/step - loss: 0.8030 - accuracy: 0.7203 - val_loss: 0.7708 - val_accuracy: 0.7389\n",
      "Epoch 28/100\n",
      "666/666 [==============================] - 807s 1s/step - loss: 0.7958 - accuracy: 0.7248 - val_loss: 0.8327 - val_accuracy: 0.7097\n",
      "Epoch 29/100\n",
      "666/666 [==============================] - 809s 1s/step - loss: 0.7889 - accuracy: 0.7253 - val_loss: 0.7950 - val_accuracy: 0.7282\n",
      "Epoch 30/100\n",
      "666/666 [==============================] - 808s 1s/step - loss: 0.7792 - accuracy: 0.7337 - val_loss: 0.7137 - val_accuracy: 0.7606\n",
      "Epoch 31/100\n",
      "666/666 [==============================] - 805s 1s/step - loss: 0.7617 - accuracy: 0.7359 - val_loss: 0.7946 - val_accuracy: 0.7193\n",
      "Epoch 32/100\n",
      "666/666 [==============================] - 927s 1s/step - loss: 0.7721 - accuracy: 0.7311 - val_loss: 0.7856 - val_accuracy: 0.7305\n",
      "Epoch 33/100\n",
      "666/666 [==============================] - 1352s 2s/step - loss: 0.7636 - accuracy: 0.7352 - val_loss: 0.7408 - val_accuracy: 0.7469\n",
      "Epoch 34/100\n",
      "666/666 [==============================] - 1281s 2s/step - loss: 0.7643 - accuracy: 0.7353 - val_loss: 0.7253 - val_accuracy: 0.7588\n",
      "Epoch 35/100\n",
      "666/666 [==============================] - 1281s 2s/step - loss: 0.7537 - accuracy: 0.7385 - val_loss: 0.7605 - val_accuracy: 0.7291\n",
      "Epoch 36/100\n",
      "666/666 [==============================] - 1275s 2s/step - loss: 0.7532 - accuracy: 0.7405 - val_loss: 0.8118 - val_accuracy: 0.7138\n",
      "Epoch 37/100\n",
      "666/666 [==============================] - 1265s 2s/step - loss: 0.7461 - accuracy: 0.7427 - val_loss: 0.7090 - val_accuracy: 0.7629\n",
      "Epoch 38/100\n",
      "666/666 [==============================] - 1263s 2s/step - loss: 0.7372 - accuracy: 0.7457 - val_loss: 0.7595 - val_accuracy: 0.7417\n",
      "Epoch 39/100\n",
      "666/666 [==============================] - 1261s 2s/step - loss: 0.7390 - accuracy: 0.7449 - val_loss: 0.7832 - val_accuracy: 0.7248\n",
      "Epoch 40/100\n",
      "666/666 [==============================] - 1123s 2s/step - loss: 0.7324 - accuracy: 0.7442 - val_loss: 0.6932 - val_accuracy: 0.7659\n",
      "Epoch 41/100\n",
      "666/666 [==============================] - 775s 1s/step - loss: 0.7288 - accuracy: 0.7477 - val_loss: 0.6871 - val_accuracy: 0.7734\n",
      "Epoch 42/100\n",
      "666/666 [==============================] - 795s 1s/step - loss: 0.7284 - accuracy: 0.7478 - val_loss: 0.7127 - val_accuracy: 0.7608\n",
      "Epoch 43/100\n",
      "666/666 [==============================] - 892s 1s/step - loss: 0.7194 - accuracy: 0.7517 - val_loss: 0.6841 - val_accuracy: 0.7688\n",
      "Epoch 44/100\n",
      "666/666 [==============================] - 974s 1s/step - loss: 0.7218 - accuracy: 0.7529 - val_loss: 0.7125 - val_accuracy: 0.7581\n",
      "Epoch 45/100\n",
      "666/666 [==============================] - 1343s 2s/step - loss: 0.7138 - accuracy: 0.7508 - val_loss: 0.7145 - val_accuracy: 0.7613\n",
      "Epoch 46/100\n",
      "666/666 [==============================] - 1343s 2s/step - loss: 0.7123 - accuracy: 0.7546 - val_loss: 0.7280 - val_accuracy: 0.7529\n",
      "Epoch 47/100\n",
      "666/666 [==============================] - 816s 1s/step - loss: 0.6958 - accuracy: 0.7599 - val_loss: 0.7587 - val_accuracy: 0.7373\n",
      "Epoch 48/100\n",
      "666/666 [==============================] - 792s 1s/step - loss: 0.6980 - accuracy: 0.7587 - val_loss: 0.6729 - val_accuracy: 0.7748\n",
      "Epoch 49/100\n",
      "666/666 [==============================] - 797s 1s/step - loss: 0.7073 - accuracy: 0.7564 - val_loss: 0.7737 - val_accuracy: 0.7412\n",
      "Epoch 50/100\n",
      "666/666 [==============================] - 796s 1s/step - loss: 0.7094 - accuracy: 0.7586 - val_loss: 0.6921 - val_accuracy: 0.7702\n",
      "Epoch 51/100\n",
      "666/666 [==============================] - 769s 1s/step - loss: 0.6985 - accuracy: 0.7601 - val_loss: 0.7318 - val_accuracy: 0.7515\n",
      "Epoch 52/100\n",
      "666/666 [==============================] - 768s 1s/step - loss: 0.6897 - accuracy: 0.7629 - val_loss: 0.6862 - val_accuracy: 0.7634\n",
      "Epoch 53/100\n",
      "666/666 [==============================] - 769s 1s/step - loss: 0.6869 - accuracy: 0.7614 - val_loss: 0.7466 - val_accuracy: 0.7510\n",
      "Epoch 54/100\n",
      "666/666 [==============================] - 768s 1s/step - loss: 0.6759 - accuracy: 0.7668 - val_loss: 0.7377 - val_accuracy: 0.7462\n",
      "Epoch 55/100\n",
      "666/666 [==============================] - 768s 1s/step - loss: 0.6823 - accuracy: 0.7641 - val_loss: 0.7291 - val_accuracy: 0.7524\n",
      "Epoch 56/100\n",
      "666/666 [==============================] - 766s 1s/step - loss: 0.6745 - accuracy: 0.7662 - val_loss: 0.7341 - val_accuracy: 0.7455\n",
      "Epoch 57/100\n",
      "666/666 [==============================] - 767s 1s/step - loss: 0.6834 - accuracy: 0.7637 - val_loss: 0.6712 - val_accuracy: 0.7707\n",
      "Epoch 58/100\n",
      "666/666 [==============================] - 771s 1s/step - loss: 0.6704 - accuracy: 0.7697 - val_loss: 0.7271 - val_accuracy: 0.7517\n",
      "Epoch 59/100\n",
      "666/666 [==============================] - 769s 1s/step - loss: 0.6685 - accuracy: 0.7664 - val_loss: 0.7047 - val_accuracy: 0.7581\n",
      "Epoch 60/100\n",
      "666/666 [==============================] - 769s 1s/step - loss: 0.6757 - accuracy: 0.7698 - val_loss: 0.6491 - val_accuracy: 0.7857\n",
      "Epoch 61/100\n",
      "666/666 [==============================] - 768s 1s/step - loss: 0.6698 - accuracy: 0.7688 - val_loss: 0.6971 - val_accuracy: 0.7622\n",
      "Epoch 62/100\n",
      "666/666 [==============================] - 770s 1s/step - loss: 0.6637 - accuracy: 0.7730 - val_loss: 0.7108 - val_accuracy: 0.7627\n",
      "Epoch 63/100\n",
      "666/666 [==============================] - 768s 1s/step - loss: 0.6659 - accuracy: 0.7704 - val_loss: 0.7336 - val_accuracy: 0.7467\n",
      "Epoch 64/100\n",
      "666/666 [==============================] - 768s 1s/step - loss: 0.6561 - accuracy: 0.7749 - val_loss: 0.6819 - val_accuracy: 0.7684\n",
      "Epoch 65/100\n",
      "666/666 [==============================] - 768s 1s/step - loss: 0.6492 - accuracy: 0.7764 - val_loss: 0.6697 - val_accuracy: 0.7766\n",
      "Epoch 66/100\n",
      "666/666 [==============================] - 771s 1s/step - loss: 0.6592 - accuracy: 0.7749 - val_loss: 0.6841 - val_accuracy: 0.7666\n",
      "Epoch 67/100\n",
      "666/666 [==============================] - 768s 1s/step - loss: 0.6517 - accuracy: 0.7762 - val_loss: 0.7379 - val_accuracy: 0.7519\n",
      "Epoch 68/100\n",
      "666/666 [==============================] - 770s 1s/step - loss: 0.6459 - accuracy: 0.7787 - val_loss: 0.6930 - val_accuracy: 0.7677\n",
      "Epoch 69/100\n",
      "666/666 [==============================] - 769s 1s/step - loss: 0.6429 - accuracy: 0.7816 - val_loss: 0.6904 - val_accuracy: 0.7624\n",
      "Epoch 70/100\n",
      "666/666 [==============================] - 771s 1s/step - loss: 0.6472 - accuracy: 0.7751 - val_loss: 0.6770 - val_accuracy: 0.7748\n",
      "Epoch 71/100\n",
      "666/666 [==============================] - 771s 1s/step - loss: 0.6395 - accuracy: 0.7787 - val_loss: 0.6428 - val_accuracy: 0.7819\n",
      "Epoch 72/100\n",
      "666/666 [==============================] - 770s 1s/step - loss: 0.6445 - accuracy: 0.7798 - val_loss: 0.6415 - val_accuracy: 0.7871\n",
      "Epoch 73/100\n",
      "666/666 [==============================] - 770s 1s/step - loss: 0.6424 - accuracy: 0.7808 - val_loss: 0.6484 - val_accuracy: 0.7807\n",
      "Epoch 74/100\n",
      "666/666 [==============================] - 768s 1s/step - loss: 0.6453 - accuracy: 0.7788 - val_loss: 0.6473 - val_accuracy: 0.7853\n",
      "Epoch 75/100\n",
      "666/666 [==============================] - 766s 1s/step - loss: 0.6361 - accuracy: 0.7830 - val_loss: 0.6696 - val_accuracy: 0.7693\n",
      "Epoch 76/100\n",
      "666/666 [==============================] - 771s 1s/step - loss: 0.6286 - accuracy: 0.7844 - val_loss: 0.6600 - val_accuracy: 0.7830\n",
      "Epoch 77/100\n",
      "666/666 [==============================] - 769s 1s/step - loss: 0.6303 - accuracy: 0.7824 - val_loss: 0.6559 - val_accuracy: 0.7798\n",
      "Epoch 78/100\n",
      "666/666 [==============================] - 771s 1s/step - loss: 0.6417 - accuracy: 0.7787 - val_loss: 0.7252 - val_accuracy: 0.7631\n",
      "Epoch 79/100\n",
      "666/666 [==============================] - 770s 1s/step - loss: 0.6319 - accuracy: 0.7854 - val_loss: 0.6366 - val_accuracy: 0.7880\n",
      "Epoch 80/100\n",
      "666/666 [==============================] - 770s 1s/step - loss: 0.6301 - accuracy: 0.7843 - val_loss: 0.6451 - val_accuracy: 0.7853\n",
      "Epoch 81/100\n",
      "666/666 [==============================] - 768s 1s/step - loss: 0.6339 - accuracy: 0.7797 - val_loss: 0.6329 - val_accuracy: 0.7883\n",
      "Epoch 82/100\n",
      "666/666 [==============================] - 768s 1s/step - loss: 0.6349 - accuracy: 0.7842 - val_loss: 0.6606 - val_accuracy: 0.7739\n",
      "Epoch 83/100\n",
      "666/666 [==============================] - 769s 1s/step - loss: 0.6182 - accuracy: 0.7891 - val_loss: 0.6299 - val_accuracy: 0.7894\n",
      "Epoch 84/100\n",
      "666/666 [==============================] - 769s 1s/step - loss: 0.6238 - accuracy: 0.7876 - val_loss: 0.6549 - val_accuracy: 0.7775\n",
      "Epoch 85/100\n",
      "666/666 [==============================] - 770s 1s/step - loss: 0.6240 - accuracy: 0.7862 - val_loss: 0.6614 - val_accuracy: 0.7775\n",
      "Epoch 86/100\n",
      "666/666 [==============================] - 770s 1s/step - loss: 0.6259 - accuracy: 0.7849 - val_loss: 0.6876 - val_accuracy: 0.7748\n",
      "Epoch 87/100\n",
      "666/666 [==============================] - 772s 1s/step - loss: 0.6090 - accuracy: 0.7894 - val_loss: 0.6608 - val_accuracy: 0.7691\n",
      "Epoch 88/100\n",
      "666/666 [==============================] - 771s 1s/step - loss: 0.6075 - accuracy: 0.7909 - val_loss: 0.6333 - val_accuracy: 0.7896\n",
      "Epoch 89/100\n",
      "666/666 [==============================] - 1099s 2s/step - loss: 0.6151 - accuracy: 0.7916 - val_loss: 0.6427 - val_accuracy: 0.7841\n",
      "Epoch 90/100\n",
      "666/666 [==============================] - 1370s 2s/step - loss: 0.6143 - accuracy: 0.7889 - val_loss: 0.6341 - val_accuracy: 0.7832\n",
      "Epoch 91/100\n",
      "666/666 [==============================] - 1348s 2s/step - loss: 0.6090 - accuracy: 0.7879 - val_loss: 0.6586 - val_accuracy: 0.7803\n",
      "Epoch 92/100\n",
      "666/666 [==============================] - 979s 1s/step - loss: 0.6149 - accuracy: 0.7886 - val_loss: 0.6669 - val_accuracy: 0.7736\n",
      "Epoch 93/100\n",
      "666/666 [==============================] - 789s 1s/step - loss: 0.6043 - accuracy: 0.7923 - val_loss: 0.6169 - val_accuracy: 0.7917\n",
      "Epoch 94/100\n",
      "666/666 [==============================] - 819s 1s/step - loss: 0.5981 - accuracy: 0.7956 - val_loss: 0.7086 - val_accuracy: 0.7698\n",
      "Epoch 95/100\n",
      "666/666 [==============================] - 807s 1s/step - loss: 0.5997 - accuracy: 0.7969 - val_loss: 0.6337 - val_accuracy: 0.7908\n",
      "Epoch 96/100\n",
      "666/666 [==============================] - 790s 1s/step - loss: 0.6021 - accuracy: 0.7932 - val_loss: 0.6567 - val_accuracy: 0.7791\n",
      "Epoch 97/100\n",
      "666/666 [==============================] - 780s 1s/step - loss: 0.5964 - accuracy: 0.7963 - val_loss: 0.6706 - val_accuracy: 0.7736\n",
      "Epoch 98/100\n",
      "666/666 [==============================] - 783s 1s/step - loss: 0.5983 - accuracy: 0.7958 - val_loss: 0.6621 - val_accuracy: 0.7775\n",
      "Epoch 99/100\n",
      "666/666 [==============================] - 795s 1s/step - loss: 0.5923 - accuracy: 0.7984 - val_loss: 0.6511 - val_accuracy: 0.7878\n",
      "Epoch 100/100\n",
      "666/666 [==============================] - 828s 1s/step - loss: 0.5933 - accuracy: 0.7939 - val_loss: 0.6617 - val_accuracy: 0.7814\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dc0f9deb88>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_it,\n",
    "          validation_data=val_it, \n",
    "          epochs= 100,\n",
    "          #steps_per_epoch = 665, #datasize/batchsize = 21284/32\n",
    "          #callbacks=[callback]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "saved_model = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(saved_model)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "accuracy: 82.53%\n"
     ]
    }
   ],
   "source": [
    "loaded_model.compile(loss = \"categorical_crossentropy\",\n",
    "             optimizer = \"adam\",\n",
    "             metrics = ['accuracy'])\n",
    "score = loaded_model.evaluate(train_it, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:myenv]",
   "language": "python",
   "name": "conda-env-myenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
